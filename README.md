# MSc Project Submission
Karan Kaushik  


### Repository
`https://github.com/Karan96Kaushik/EmoSoNet`

# Emotionally-Driven Music Generation Using UNET Diffusion DDPM: A Comparative Analysis of Self-Attention Mechanisms

## Introduction
This is source code for the accompanying research paper which proposes a UNet using Self Attention and trained using transfer learning using MIDI music files from LakhMIDI and EMOPIA datasets. The purpose of this model is to replicate the emotional categories of music files as categorized by the EMOPIA dataset.        

### Preprocessor 

The preprocessor uses the LakhMIDI dataset and EMOPIA   

The preprocessing notebook `midi-data-processor.ipynb` is included which generates   

The output was ported to a Kaggle Dataset and used as input for the model before the training process and is available at `https://www.kaggle.com/datasets/karank96/midi-numpy-array`

### Training Notebook
The final version of the training notebook including the model weights are available at the following link:    
`https://www.kaggle.com/bayonetbaron/midi-music-diffusion-unet-24-aug-23`   

Training can be started by running the notebook named `emotion-based-midi-music-diffusion-unet-24-aug-23.ipynb` which starts the training process and saves the model weights in the current directory.   
Please note that training takes place in 2 phases which have to be enabled and executed individually from the notebook, one for pretraining and the other for finetuning as metioned in the paper.   
Also note that the Self Attention blocks have to be enabled in the notebook

### Testing

New samples can be generated by running the python file using `generate_samples.py`, this will generate and save 3 samples of music files in the MIDI format.

## Other Files
1. Survey Results.xlsx - This includes responses to questions about individual clips of music as given by listeners about the perceived Valence, Arousal and Quality of the clip.
    1. fileRef Column - this refers to the category of sample (RF - real file, SA - with self attention, NA - no self attention)
1. *.pt - Weight Files - These are trained weight files
    1. \*base\*.pt - These are weight files after training on LakhMIDI and is used to further train the model on EMOPIA
    1. \*q\*.pt - These are weight files after training on EMOPIA and are final weights that can be used to generate MIDI samples# EmoSoNet
